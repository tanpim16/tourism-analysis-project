import pandas as pd
from pytrends.request import TrendReq
import time
import random
import os

def fetch_comprehensive_trends(provinces_df):
    """
    ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Google Trends ‡πÅ‡∏¢‡∏Å‡πÄ‡∏õ‡πá‡∏ô 2 Category: 
    1. Thai Intent (‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß + ‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î)
    2. Foreign Intent (Province Name + Tourism)
    """
    pytrends = TrendReq(hl='th-TH', tz=360, retries=5, backoff_factor=1)
    
    all_combined_data = []
    chunk_size = 5 # Google Limit
    
    # ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏±‡πâ‡∏á‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
    provinces_th = provinces_df['ProvinceThai'].tolist()
    provinces_en = provinces_df['ProvinceEN'].tolist()

    for i in range(0, len(provinces_th), chunk_size):
        chunk_th = provinces_th[i : i + chunk_size]
        chunk_en = provinces_en[i : i + chunk_size]
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∏‡∏î Keywords 2 ‡πÅ‡∏ö‡∏ö‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ï‡∏ö‡πÑ‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡∏Å‡∏±‡∏ô
        # 1. ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏® (Thai)
        kw_thai = [f"‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß{p}" for p in chunk_th]
        # 2. ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏•‡∏≤‡∏î‡∏ï‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏® (Foreign)
        kw_foreign = [f"{p} Tourism" for p in chunk_en]

        # --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏±‡πà‡∏á‡πÑ‡∏ó‡∏¢ ---
        print(f"üì° [{i//chunk_size + 1}] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏±‡πà‡∏á‡πÑ‡∏ó‡∏¢: {kw_thai}...")
        df_thai = get_trends_data(pytrends, kw_thai, "Thai_Intent")
        if df_thai is not None:
            all_combined_data.append(df_thai)
        
        # ‡∏û‡∏±‡∏Å‡πÄ‡∏ö‡∏£‡∏Å‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏î‡∏∂‡∏á‡∏ä‡∏∏‡∏î‡πÑ‡∏ó‡∏¢‡∏Å‡∏±‡∏ö‡∏ï‡πà‡∏≤‡∏á‡∏ä‡∏≤‡∏ï‡∏¥
        time.sleep(random.uniform(3, 6))

        # --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏±‡πà‡∏á‡∏ï‡πà‡∏≤‡∏á‡∏ä‡∏≤‡∏ï‡∏¥ ---
        print(f"üì° [{i//chunk_size + 1}] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏±‡πà‡∏á‡∏ï‡πà‡∏≤‡∏á‡∏ä‡∏≤‡∏ï‡∏¥: {kw_foreign}...")
        df_foreign = get_trends_data(pytrends, kw_foreign, "Foreign_Intent")
        if df_foreign is not None:
            # Map ‡∏ä‡∏∑‡πà‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ Merge ‡∏á‡πà‡∏≤‡∏¢
            en_to_th = dict(zip(kw_foreign, chunk_th))
            df_foreign['ProvinceThai'] = df_foreign['Keyword'].map(en_to_th)
            all_combined_data.append(df_foreign)

        # --- ‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÇ‡∏î‡∏ô‡πÅ‡∏ö‡∏ô (Cooldown) ---
        wait_time = random.uniform(8, 15)
        if (i // chunk_size) % 2 == 0 and i > 0:
            print("üí§ ‡∏û‡∏±‡∏Å‡πÄ‡∏ö‡∏£‡∏Å‡∏¢‡∏≤‡∏ß 30 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ö‡∏≠‡∏ó...")
            wait_time += 20
        
        print(f"‚è≥ ‡∏£‡∏≠ {wait_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ... \n")
        time.sleep(wait_time)

    # --- ‡∏£‡∏ß‡∏°‡∏£‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏¢‡∏∏‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Aggregation) ---
    if all_combined_data:
        full_df = pd.concat(all_combined_data, ignore_index=True)
        print("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏¢‡∏∏‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå -> ‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏õ‡∏µ ‡∏û.‡∏®./‡∏Ñ.‡∏®. ...")
        
        # 1. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
        full_df['Year_AD'] = full_df['date'].dt.year
        full_df['Year_BE'] = full_df['Year_AD'] + 543
        full_df['Month'] = full_df['date'].dt.strftime('%b')

        # 2. Groupby ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏° Category
        final_df = full_df.groupby(
            ['ProvinceThai', 'Year_AD', 'Year_BE', 'Month', 'Category'], 
            as_index=False
        )['Search_Interest'].mean()

        final_df['Search_Interest'] = final_df['Search_Interest'].round(2)
        return final_df
    
    return None

def get_trends_data(pytrends_obj, keywords, category_name):
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Error"""
    try:
        pytrends_obj.build_payload(keywords, cat=67, timeframe='2023-01-01 2025-12-31', geo='TH')
        df = pytrends_obj.interest_over_time()
        
        if not df.empty:
            df = df.drop(columns=['isPartial']).reset_index()
            # Melt ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏¢‡∏≤‡∏ß
            df_long = df.melt(id_vars=['date'], value_vars=keywords, 
                              var_name='Keyword', value_name='Search_Interest')
            df_long['Category'] = category_name
            
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ù‡∏±‡πà‡∏á‡πÑ‡∏ó‡∏¢ ‡πÉ‡∏´‡πâ‡∏™‡∏Å‡∏±‡∏î‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÑ‡∏ß‡πâ‡πÄ‡∏•‡∏¢
            if category_name == "Thai_Intent":
                df_long['ProvinceThai'] = df_long['Keyword'].str.replace('‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß', '', regex=False)
            
            return df_long
    except Exception as e:
        print(f"‚ö†Ô∏è Error ‡πÉ‡∏ô‡∏´‡∏°‡∏ß‡∏î {category_name}: {e}")
        return None

if __name__ == "__main__":
    input_path = 'data/processed/ProvinceThailandList.csv'
    output_path = 'data/processed/Google_Trends_Data.csv'

    if os.path.exists(input_path):
        prov_df = pd.read_csv(input_path)
        final_result = fetch_comprehensive_trends(prov_df)

        if final_result is not None:
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            final_result.to_csv(output_path, index=False, encoding='utf-8-sig')
            print(f"üéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå! ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà: {output_path}")
            print(final_result.sample(10)) # ‡∏™‡∏∏‡πà‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏≤‡πÇ‡∏ä‡∏ß‡πå 10 ‡πÅ‡∏ñ‡∏ß
    else:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î!")