import pandas as pd
from pytrends.request import TrendReq
import time
import random
import os

def fetch_google_trends_thailand(provinces_list):
    # 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ pytrends
    # hl=th-TH (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢), tz=360 (Timezone ‡πÑ‡∏ó‡∏¢)
    pytrends = TrendReq(hl='th-TH', tz=360, retries=5, backoff_factor=1)
    
    all_data = []
    chunk_size = 5 # Google ‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á‡πÑ‡∏î‡πâ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏•‡∏∞ 5 keywords
    
    for i in range(0, len(provinces_list), chunk_size):
        chunk = provinces_list[i : i + chunk_size]
        keywords = [f"‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß{p}" for p in chunk]
        
        print(f"üì° ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏∏‡πà‡∏° {i//chunk_size + 1}: {keywords}...")
        
        try:
            # 2. ‡∏™‡πà‡∏á Request (cat=67 ‡∏Ñ‡∏∑‡∏≠‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà Travel)
            # ‡∏î‡∏∂‡∏á‡∏ä‡πà‡∏ß‡∏á‡∏õ‡∏µ 2023-2025 (‡∏Ñ.‡∏®.)
            pytrends.build_payload(
                keywords, 
                cat=67, 
                timeframe='2023-01-01 2025-12-31', 
                geo='TH'
            )
            
            df = pytrends.interest_over_time()
            
            if not df.empty:
                df = df.drop(columns=['isPartial']).reset_index()
                
                # ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÅ‡∏ô‡∏ß‡∏ô‡∏≠‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ô‡∏ß‡∏ï‡∏±‡πâ‡∏á (Melt)
                df_melted = df.melt(id_vars=['date'], value_vars=keywords, 
                                    var_name='Keyword', value_name='Search_Interest')
                
                # ‡∏™‡∏Å‡∏±‡∏î‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î (‡∏•‡∏ö‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ '‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß' ‡∏≠‡∏≠‡∏Å)
                df_melted['ProvinceThai'] = df_melted['Keyword'].str.replace('‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß', '', regex=False)
                
                # 3. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á "‡∏õ‡∏µ" (‡∏Ñ.‡∏®. ‡πÅ‡∏•‡∏∞ ‡∏û.‡∏®.) ‡πÅ‡∏•‡∏∞ "‡πÄ‡∏î‡∏∑‡∏≠‡∏ô"
                df_melted['Year_AD'] = df_melted['date'].dt.year  # ‡∏õ‡∏µ ‡∏Ñ.‡∏®.
                df_melted['Year_BE'] = df_melted['Year_AD'] + 543 # ‡∏õ‡∏µ ‡∏û.‡∏®.
                df_melted['Month'] = df_melted['date'].dt.strftime('%b') # ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏¢‡πà‡∏≠ (Jan, Feb...)
                
                all_data.append(df_melted)
                print(f"‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
            
            # 4. üõ°Ô∏è ‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÇ‡∏î‡∏ô‡πÅ‡∏ö‡∏ô (Cooldown)
            wait_time = random.uniform(5, 12)
            if (i // chunk_size) % 3 == 0 and i > 0:
                print("üí§ ‡∏û‡∏±‡∏Å‡πÄ‡∏ö‡∏£‡∏Å‡∏¢‡∏≤‡∏ß 20 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢...")
                wait_time += 20
                
            time.sleep(wait_time)
            
        except Exception as e:
            print(f"‚ùå Error ‡∏Å‡∏•‡∏∏‡πà‡∏° {chunk}: {e}")
            print("üí§ ‡∏û‡∏±‡∏Å 60 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏∞‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà...")
            time.sleep(60)
            continue

    if all_data:
        # --- üåü ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£ Aggregation (‡∏¢‡∏∏‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô) üåü ---
        raw_df = pd.concat(all_data, ignore_index=True)
        
        print("\nüîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏¢‡∏∏‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå -> ‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô...")
        
        # ‡∏¢‡∏∏‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ (Mean) ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤
        final_df = raw_df.groupby(
            ['ProvinceThai', 'Year_AD', 'Year_BE', 'Month'], 
            as_index=False
        )['Search_Interest'].mean()
        
        # ‡∏õ‡∏±‡∏î‡πÄ‡∏®‡∏©‡∏ó‡∏®‡∏ô‡∏¥‡∏¢‡∏°
        final_df['Search_Interest'] = final_df['Search_Interest'].round(2)
        
        return final_df
    return None

if __name__ == "__main__":
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Path ‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
    input_prov = 'data/processed/ProvinceThailandList.csv'
    output_file = 'data/processed/Google_Trends_Data.csv'
    
    if os.path.exists(input_prov):
        df_prov = pd.read_csv(input_prov)
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå ProvinceThai
        provinces = df_prov['ProvinceThai'].unique().tolist()
        
        # ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        result_df = fetch_google_trends_thailand(provinces)
        
        if result_df is not None:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
            os.makedirs(os.path.dirname(output_file), exist_ok=True)
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå
            result_df.to_csv(output_file, index=False, encoding='utf-8-sig')
            print(f"\nüéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå! ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà: {output_file}")
            print(result_df.head())
    else:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà: {input_prov}")